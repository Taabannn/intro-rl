# Homework 4
### Part 1
A Q-Learning-based agent has been utilized in two cases (one with constant learning rate and another with decaying learning rate) to train Taxi-v3 task and the average return 
has been plotted.
### Part 2
A method is wrritten to find the exact number of reachable states.
### Part 3
Moreover, Sarsa and Tree Back up n-step (with three different values of n) are implemented to compare the convergence rates and the steady value of the average return.
### Part 4
An off-policy Monte Carlo agent with epsilon-greedy behavior policy has been utilized in two cases (one with constant learning rate and another with decaying learning rate) and the average return 
(with low convergence rate) has been plotted.